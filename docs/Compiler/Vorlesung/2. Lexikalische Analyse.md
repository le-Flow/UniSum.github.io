##  **Kontextfreie Grammatiken**

CFGs sind das Werkzeug, um die **Syntax** einer Programmiersprache zu beschreiben (z. B. "Wie sieht eine If-Anweisung aus?", "Wie werden Klammern geschachtelt?"). Sie sind mächtiger als Reguläre Ausdrücke, da sie **Rekursion** (Verschachtelung) darstellen können.

### **Formale Definition**
Im Compilerbau wird eine Grammatik $G$ oft als 4-Tupel definiert:
$$G = (N, T, P, S)$$

* **$N$ (Nicht-Terminale):** Platzhalter oder Variablen, die weiter aufgelöst werden müssen (z. B. `<Statement>`, `<Expression>`, `<If-Block>`).
* **$T$ (Terminale):** Die kleinsten Bausteine, die nicht weiter zerlegt werden. Im Compiler sind das die **Tokens**, die vom Lexer kommen (z. B. `if`, `int`, `id`, `;`, `+`).
* **$P$ (Produktionsregeln):** Regeln der Form $A \rightarrow \alpha$, wobei $A \in N$ ist und $\alpha$ eine Folge von Terminalen und Nicht-Terminalen.
  * *Beispiel:* $E \rightarrow E + E$
* **$S$ (Startsymbol):** Das Nicht-Terminal, bei dem die Analyse beginnt (oft `<Program>`).


Hier ist die Zusammenfassung zum **Parsebaum** (oft auch **CST - Concrete Syntax Tree** genannt), fokussiert auf das, was du für das Verständnis der Syntaxanalyse brauchst.

Der Parsebaum ist die **grafische Darstellung der Ableitung**. Er beweist, dass ein Tokenstrom tatsächlich zur Grammatik passt.


## **Parsebäume**

### **Aufbau (Anatomie)**
Jedes Element im Baum entspricht exakt den Mengen aus der Grammatik ($N, T, S$):

* **Wurzel (Root):** Das Startsymbol $S$.
* **Innere Knoten (Nodes):** Die Nicht-Terminale ($N$), also die Regeln (z. B. `<Expr>`, `<Stmt>`).
* **Blätter (Leaves):** Die Terminale ($T$), also die **Tokens**, die vom Lexer kamen (z. B. `id`, `+`, `;`).

### **Konkreter Syntaxbaum (Parsebaum)**
* **1:1 Abbild der Grammatik:** Jeder Ast entspricht genau einer angewendeten Produktionsregel.
* **Vollständig:** Er enthält **jedes einzelne Zeichen**, das der Parser verarbeitet hat, auch syntaktischen "Zucker" wie Klammern `( )`, Semikolons `;` oder Kommas, die für die spätere Logik eigentlich unwichtig sind.
* **Hierarchie:** Die Struktur des Baums zeigt die **Bindung** (Präzedenz) von Operatoren.
  * **Regel:** Was im Baum **tiefer** steht, wird zuerst ausgewertet (engere Bindung).


### **Abstrakter Syntaxbaum (AST)**

* **Kondensierte Logik:** Eine bereinigte Version des Parsebaums, die nur die für die Semantik (Bedeutung) relevanten Informationen enthält.
* **Kein syntaktischer "Zucker":** Hilfszeichen, die nur für den Parser nötig waren (wie Klammern `( )`, Semikolons `;` oder Keywords wie `then`), werden entfernt. Die Struktur des Baums selbst definiert nun die Zusammengehörigkeit (die Klammerung ist implizit).
* **Operatoren als Knoten:** Während im CST die Knoten abstrakte *Regelnamen* sind (z. B. `<Expr>`), sind die inneren Knoten im AST meist direkt die **Operatoren** oder **Anweisungen** (z. B. ein `PLUS`-Knoten, der direkt zwei Unterbäume als Operanden hat).

### **CST vs. AST**
Das ist die klassische Prüfungsfrage. Warum nutzen wir später meist keinen Parsebaum mehr?

| Merkmal | Parsebaum (CST) | Abstrakter Syntaxbaum (AST) |
| :--- | :--- | :--- |
| **Inhalt** | Enthält **alles** (Klammern, Keywords like `if`, `then`). | Enthält nur **Logik** (Operationen und Operanden). |
| **Knoten** | Nicht-Terminale der Grammatik. | Operatoren oder Anweisungen. |
| **Größe** | Riesig, tief verschachtelt (z. B. `Expr -> Term -> Factor -> Number`). | Kompakt, flach. |
| **Zweck** | Dient dem Parser zur Validierung der Syntax. | Dient dem Rest des Compilers (Semantik, Code-Gen). |

### **Mehrdeutigkeit im Baum**
Wie vorhin bei den Grammatiken erwähnt: Wenn du für **einen** Input **zwei verschiedene** Parsebäume zeichnen kannst, ist die Grammatik **mehrdeutig** (Ambiguous).

* Beispiel: `3 + 4 * 5`.
* Baum A gruppiert `(3+4)` tiefer $\rightarrow$ falsch.
* Baum B gruppiert `(4*5)` tiefer $\rightarrow$ richtig (wegen Punkt-vor-Strich).

## **Lexer**

### **Hauptaufgabe**
Der Lexer ist die erste Stufe des Compilers. Er wandelt den **rohen Zeichenstrom** (Source Code) in eine **Folge von Tokens** um.

* **Input:** Quellprogramm (Buchstaben, Ziffern, Sonderzeichen).
* **Output:** Tokens für den Parser.

### **Konkrete Tätigkeiten**
* **Tokenisierung:** Erfasst zusammengehörige Zeichen als logische Einheiten (z. B. `if`, `123`, `variableName`).
* **Bereinigung:** Entfernt alles, was für die Syntax irrelevant ist (Leerzeichen, Tabs, Zeilenumbrüche, Kommentare).
* **Symboltabelle:** Erstellt oft schon erste Einträge in der Symboltabelle (z. B. für Bezeichner).

### **Funktionsweise & Interaktion**
Der Lexer arbeitet nicht auf Vorrat, sondern **"on demand"**:

* Der **Parser** ruft `getNextToken` auf.
* Der Lexer liest den Input und sucht die **längste Zeichenfolge** (Longest Match / Maximal Munch), die auf ein Token-Muster passt.
* Er gibt dieses Token an den Parser zurück.

### **Erstellung**
Man schreibt Lexer selten komplett per Hand, sondern nutzt **Scanner-Generatoren** (wie **JFlex** oder Lex/Flex).

* **Eingabe:** Reguläre Ausdrücke für jedes Token.
* **Ausgabe des Tools:** Fertiger Code (in Java oder C), der einen **Endlichen Automaten** implementiert.

### **Fehlerbehandlung**
Der Lexer versteht keine Logik oder komplexe Syntax (er weiß nicht, ob `i(x)` ein Tippfehler für `if(x)` ist).

* **Wenn kein Muster passt:** Der Lexer darf nicht abstürzen (Crash/Exception sind verboten!).
* **Lösung:** **"Panikmodus"**. Er löscht/ignoriert einfach so lange Eingabezeichen (z. B. bis zum Zeilenende), bis er wieder ein bekanntes Token erkennen kann.

## **JFlex**

### **Grundstruktur einer .jflex Datei**

JFlex-Dateien sind in **drei Abschnitte** unterteilt, die durch `%%` getrennt werden.

```jflex
/* 1. USER CODE (Imports, Package) */
package mein.compiler;
import java_cup.runtime.*;

%%

/* 2. OPTIONEN & MAKROS */
%class MeinLexer
%unicode
%line
%column

/* Makro-Definitionen */
Digit = [0-9]
Letter = [a-zA-Z]

%%

/* 3. REGELN (Lexical Rules) */
/* Syntax:  Regex   { Java Code } */

"if"         { return symbol(sym.IF); }
{Digit}+     { return symbol(sym.NUM, Integer.parseInt(yytext())); }
.            { throw new Error("Unerwartetes Zeichen"); }
```

### **Wichtige Operatoren & Syntax**

Wie man Muster definiert.

| Operator | Beschreibung | Beispiel | Matcht... |
| :--- | :--- | :--- | :--- |
| `|` | **Oder** (Alternative) | `a | b` | "a" oder "b" |
| `*` | **Kleene-Stern** | `a*` | 0 bis unendlich viele "a" |
| `+` | **Plus** | `a+` | 1 bis unendlich viele "a" |
| `?` | **Optional** | `a?` | Kein oder ein "a" |
| `(...)` | **Gruppierung** | `(ab)+` | "ab", "abab", ... |
| `.` | **Punkt** | `.` | Jedes Zeichen (außer Newline) |
| `\` | **Escape** | `\.` | Einen echten Punkt |
| `~` | **Bis-Zu** (JFlex Special) | `~"\n"` | Alles *bis* zum Zeilenumbruch |


### **Literale vs. Regex**

In JFlex ist der Unterschied zwischen Text und Code strikt.

| Schreibweise | Bedeutung | Erklärung |
| :--- | :--- | :--- |
| **`"wort"`** | **String-Literal** | Matcht exakt die Zeichenfolge `wort`. Sonderzeichen darin (wie `*`) verlieren ihre Bedeutung. |
| **`wort`** | **Regex / Makro** | Versucht ein Makro namens `wort` zu finden oder interpretiert es als Regex. |
| **`" "`** | **Leerzeichen** | Leerzeichen müssen oft in Anführungszeichen stehen, sonst denkt JFlex, der Java-Code beginnt. |
| **`\\`** | **Backslash** | Muss auch innerhalb von Anführungszeichen escaped werden: `"\\"` matcht `\`. |

### **Makros (Definition & Nutzung)**

Makros machen den Code lesbar. Sie funktionieren wie Variablen für Regex-Teile.

**1. Definition (Abschnitt 2)**

* Links der Name, rechts der Regex.
* **Keine** geschweiften Klammern hier\!

<!-- end list -->

```jflex
Identifier = [a-zA-Z]+
Whitespace = [ \t\r\n]+
```

**2. Benutzung (Abschnitt 3)**

* Muss in **geschweifte Klammern** `{}` gesetzt werden.

<!-- end list -->

```jflex
{Identifier}   { System.out.println("ID gefunden: " + yytext()); }
{Whitespace}   { /* ignorieren */ }
```

### **Zeichenklassen**

Definition von Mengen erlaubter Zeichen.

| Syntax | Bedeutung | Beispiel |
| :--- | :--- | :--- |
| `[...]` | **Menge** | `[abc]` (a, b oder c) |
| `[ - ]` | **Bereich** | `[0-9]` (Ziffern 0-9) |
| `[^...]` | **Negation** | `[^abc]` (Alles außer a, b, c) |
| `&&` | **Schnittmenge** | `[a-z]&&[^aeiou]` (Kleinbuchstaben ohne Vokale) |


### **Matching-Reihenfolge**

Wenn mehrere Regeln auf den Input passen, entscheidet JFlex so:

1.  **Longest Match:** Die Regel, die den **längsten** String abdeckt, gewinnt.
  * *Beispiel:* Input `ifvar` → matcht `{Identifier}`, nicht `"if"`.
2.  **First Match:** Bei gleicher Länge gewinnt die Regel, die **weiter oben** in der Datei steht.
  * *Wichtig:* Spezifische Keywords (`"if"`) müssen **vor** allgemeinen Regeln (`{Identifier}`) stehen.

### **Nützliche Snippets**

**Zeilenumbruch (Plattformunabhängig):**

```jflex
LineTerminator = \r|\n|\r\n
```

**Kommentare (C-Style `/* ... */`):**

```jflex
Comment = "/*" [^*] ~"*/" | "/*" "*"+ "/"
```

*(Hinweis: Echte C-Kommentare sind etwas komplexer wegen geschachtelten Sternen, aber dies ist die einfache JFlex-Variante)*

**String-Literale (z.B. `"Hallo"`):**

```jflex
String = \"[^\"]*\"
```
