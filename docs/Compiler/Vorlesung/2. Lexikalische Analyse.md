### **Kontextfreie Grammatiken**

CFGs sind das Werkzeug, um die **Syntax** einer Programmiersprache zu beschreiben (z. B. "Wie sieht eine If-Anweisung aus?", "Wie werden Klammern geschachtelt?"). Sie sind mächtiger als Reguläre Ausdrücke, da sie **Rekursion** (Verschachtelung) darstellen können.

### **Formale Definition**

Im Compilerbau wird eine Grammatik $G$ oft als 4-Tupel definiert:

$$
G = (N, T, P, S)
$$

* **$N$ (Nicht-Terminale):** Platzhalter oder Variablen, die weiter aufgelöst werden müssen (z. B. `<Statement>`, `<Expression>`, `<If-Block>`).
* **$T$ (Terminale):** Die kleinsten Bausteine, die nicht weiter zerlegt werden. Im Compiler sind das die **Tokens**, die vom Lexer kommen (z. B. `if`, `int`, `id`, `;`, `+`).
* **$P$ (Produktionsregeln):** Regeln der Form $A \rightarrow \alpha$, wobei $A \in N$ ist und $\alpha$ eine Folge von Terminalen und Nicht-Terminalen.
  * *Beispiel:* $E \rightarrow E + E$
* **$S$ (Startsymbol):** Das Nicht-Terminal, bei dem die Analyse beginnt (oft `<Program>`).

Hier ist die Zusammenfassung zum **Parsebaum** (oft auch **CST - Concrete Syntax Tree** genannt), fokussiert auf das, was du für das Verständnis der Syntaxanalyse brauchst.

Der Parsebaum ist die **grafische Darstellung der Ableitung**. Er beweist, dass ein Tokenstrom tatsächlich zur Grammatik passt.

## **Parsebäume**

### **Aufbau (Anatomie)**

Jedes Element im Baum entspricht exakt den Mengen aus der Grammatik ($N, T, S$):

* **Wurzel (Root):** Das Startsymbol $S$.
* **Innere Knoten (Nodes):** Die Nicht-Terminale ($N$), also die Regeln (z. B. `<Expr>`, `<Stmt>`).
* **Blätter (Leaves):** Die Terminale ($T$), also die **Tokens**, die vom Lexer kamen (z. B. `id`, `+`, `;`).

### **Konkreter Syntaxbaum (Parsebaum)**

* **1:1 Abbild der Grammatik:** Jeder Ast entspricht genau einer angewendeten Produktionsregel.
* **Vollständig:** Er enthält **jedes einzelne Zeichen**, das der Parser verarbeitet hat, auch syntaktischen "Zucker" wie Klammern `( )`, Semikolons `;` oder Kommas, die für die spätere Logik eigentlich unwichtig sind.
* **Hierarchie:** Die Struktur des Baums zeigt die **Bindung** (Präzedenz) von Operatoren.
  * **Regel:** Was im Baum **tiefer** steht, wird zuerst ausgewertet (engere Bindung).

### **Abstrakter Syntaxbaum (AST)**

* **Kondensierte Logik:** Eine bereinigte Version des Parsebaums, die nur die für die Semantik (Bedeutung) relevanten Informationen enthält.
* **Kein syntaktischer "Zucker":** Hilfszeichen, die nur für den Parser nötig waren (wie Klammern `( )`, Semikolons `;` oder Keywords wie `then`), werden entfernt. Die Struktur des Baums selbst definiert nun die Zusammengehörigkeit (die Klammerung ist implizit).
* **Operatoren als Knoten:** Während im CST die Knoten abstrakte *Regelnamen* sind (z. B. `<Expr>`), sind die inneren Knoten im AST meist direkt die **Operatoren** oder **Anweisungen** (z. B. ein `PLUS`-Knoten, der direkt zwei Unterbäume als Operanden hat).

### **CST vs. AST**

Das ist die klassische Prüfungsfrage. Warum nutzen wir später meist keinen Parsebaum mehr?


| Merkmal     | Parsebaum (CST)                                                       | Abstrakter Syntaxbaum (AST)                        |
| :------------ | :---------------------------------------------------------------------- | :--------------------------------------------------- |
| **Inhalt**  | Enthält **alles** (Klammern, Keywords like `if`, `then`).             | Enthält nur **Logik** (Operationen und Operanden). |
| **Knoten**  | Nicht-Terminale der Grammatik.                                        | Operatoren oder Anweisungen.                       |
| **Größe** | Riesig, tief verschachtelt (z. B.`Expr -> Term -> Factor -> Number`). | Kompakt, flach.                                    |
| **Zweck**   | Dient dem Parser zur Validierung der Syntax.                          | Dient dem Rest des Compilers (Semantik, Code-Gen). |

### **Mehrdeutigkeit im Baum**

Wie vorhin bei den Grammatiken erwähnt: Wenn du für **einen** Input **zwei verschiedene** Parsebäume zeichnen kannst, ist die Grammatik **mehrdeutig** (Ambiguous).

* Beispiel: `3 + 4 * 5`.
* Baum A gruppiert `(3+4)` tiefer $\rightarrow$ falsch.
* Baum B gruppiert `(4*5)` tiefer $\rightarrow$ richtig (wegen Punkt-vor-Strich).

## **Lexer**

### **Hauptaufgabe**

Der Lexer ist die erste Stufe des Compilers. Er wandelt den **rohen Zeichenstrom** (Source Code) in eine **Folge von Tokens** um.

* **Input:** Quellprogramm (Buchstaben, Ziffern, Sonderzeichen).
* **Output:** Tokens für den Parser.

### **Konkrete Tätigkeiten**

* **Tokenisierung:** Erfasst zusammengehörige Zeichen als logische Einheiten (z. B. `if`, `123`, `variableName`).
* **Bereinigung:** Entfernt alles, was für die Syntax irrelevant ist (Leerzeichen, Tabs, Zeilenumbrüche, Kommentare).
* **Symboltabelle:** Erstellt oft schon erste Einträge in der Symboltabelle (z. B. für Bezeichner).

### **Funktionsweise & Interaktion**

Der Lexer arbeitet nicht auf Vorrat, sondern **"on demand"**:

* Der **Parser** ruft `getNextToken` auf.
* Der Lexer liest den Input und sucht die **längste Zeichenfolge** (Longest Match / Maximal Munch), die auf ein Token-Muster passt.
* Er gibt dieses Token an den Parser zurück.

### **Erstellung**

Man schreibt Lexer selten komplett per Hand, sondern nutzt **Scanner-Generatoren** (wie **JFlex** oder Lex/Flex).

* **Eingabe:** Reguläre Ausdrücke für jedes Token.
* **Ausgabe des Tools:** Fertiger Code (in Java oder C), der einen **Endlichen Automaten** implementiert.

### **Fehlerbehandlung**

Der Lexer versteht keine Logik oder komplexe Syntax (er weiß nicht, ob `i(x)` ein Tippfehler für `if(x)` ist).

* **Wenn kein Muster passt:** Der Lexer darf nicht abstürzen (Crash/Exception sind verboten!).
* **Lösung:** **"Panikmodus"**. Er löscht/ignoriert einfach so lange Eingabezeichen (z. B. bis zum Zeilenende), bis er wieder ein bekanntes Token erkennen kann.

## **JFlex**

### **Grundstruktur einer .jflex Datei**

JFlex-Dateien sind in **drei Abschnitte** unterteilt, die durch `%%` getrennt werden.

```jflex
/* 1. USER CODE (Imports, Package) */
package mein.compiler;
import java_cup.runtime.*;

%%

/* 2. OPTIONEN & MAKROS */
%class MeinLexer
%unicode
%line
%column

/* Makro-Definitionen */
Digit = [0-9]
Letter = [a-zA-Z]

%%

/* 3. REGELN (Lexical Rules) */
/* Syntax:  Regex   { Java Code } */

"if"         { return symbol(sym.IF); }
{Digit}+     { return symbol(sym.NUM, Integer.parseInt(yytext())); }
.            { throw new Error("Unerwartetes Zeichen"); }
```

### **Wichtige Operatoren & Syntax**

Wie man Muster definiert.


| Operator | Beschreibung               | Beispiel               | Matcht...                      |
| :--------- | :--------------------------- | :----------------------- | :------------------------------- |
| `        | `                          | **Oder** (Alternative) | `a                             |
| `*`      | **Kleene-Stern**           | `a*`                   | 0 bis unendlich viele "a"      |
| `+`      | **Plus**                   | `a+`                   | 1 bis unendlich viele "a"      |
| `?`      | **Optional**               | `a?`                   | Kein oder ein "a"              |
| `(...)`  | **Gruppierung**            | `(ab)+`                | "ab", "abab", ...              |
| `.`      | **Punkt**                  | `.`                    | Jedes Zeichen (außer Newline) |
| `\`      | **Escape**                 | `\.`                   | Einen echten Punkt             |
| `~`      | **Bis-Zu** (JFlex Special) | `~"\n"`                | Alles*bis* zum Zeilenumbruch   |

### **Literale vs. Regex**

In JFlex ist der Unterschied zwischen Text und Code strikt.


| Schreibweise | Bedeutung          | Erklärung                                                                                      |
| :------------- | :------------------- | :------------------------------------------------------------------------------------------------ |
| **`"wort"`** | **String-Literal** | Matcht exakt die Zeichenfolge`wort`. Sonderzeichen darin (wie `*`) verlieren ihre Bedeutung.    |
| **`wort`**   | **Regex / Makro**  | Versucht ein Makro namens`wort` zu finden oder interpretiert es als Regex.                      |
| **`" "`**    | **Leerzeichen**    | Leerzeichen müssen oft in Anführungszeichen stehen, sonst denkt JFlex, der Java-Code beginnt. |
| **`\\`**     | **Backslash**      | Muss auch innerhalb von Anführungszeichen escaped werden:`"\\"` matcht `\`.                    |

### **Makros (Definition & Nutzung)**

Makros machen den Code lesbar. Sie funktionieren wie Variablen für Regex-Teile.

**1. Definition (Abschnitt 2)**

* Links der Name, rechts der Regex.
* **Keine** geschweiften Klammern hier\!

<!-- end list -->


```jflex
Identifier = [a-zA-Z]+
Whitespace = [ \t\r\n]+
```

**2. Benutzung (Abschnitt 3)**

* Muss in **geschweifte Klammern** `{}` gesetzt werden.

<!-- end list -->


```jflex
{Identifier}   { System.out.println("ID gefunden: " + yytext()); }
{Whitespace}   { /* ignorieren */ }
```

### **Zeichenklassen**

Definition von Mengen erlaubter Zeichen.


| Syntax   | Bedeutung        | Beispiel                                        |
| :--------- | :----------------- | :------------------------------------------------ |
| `[...]`  | **Menge**        | `[abc]` (a, b oder c)                           |
| `[ - ]`  | **Bereich**      | `[0-9]` (Ziffern 0-9)                           |
| `[^...]` | **Negation**     | `[^abc]` (Alles außer a, b, c)                 |
| `&&`     | **Schnittmenge** | `[a-z]&&[^aeiou]` (Kleinbuchstaben ohne Vokale) |

### **Matching-Reihenfolge**

Wenn mehrere Regeln auf den Input passen, entscheidet JFlex so:

1. **Longest Match:** Die Regel, die den **längsten** String abdeckt, gewinnt.

* *Beispiel:* Input `ifvar` → matcht `{Identifier}`, nicht `"if"`.

2. **First Match:** Bei gleicher Länge gewinnt die Regel, die **weiter oben** in der Datei steht.

* *Wichtig:* Spezifische Keywords (`"if"`) müssen **vor** allgemeinen Regeln (`{Identifier}`) stehen.

### **Nützliche Snippets**

**Zeilenumbruch (Plattformunabhängig):**

```jflex
LineTerminator = \r|\n|\r\n
```

**Kommentare (C-Style `/* ... */`):**

```jflex
Comment = "/*" [^*] ~"*/" | "/*" "*"+ "/"
```

*(Hinweis: Echte C-Kommentare sind etwas komplexer wegen geschachtelten Sternen, aber dies ist die einfache JFlex-Variante)*

**String-Literale (z.B. `"Hallo"`):**

```jflex
String = \"[^\"]*\"
```

## **Tokenerkennung**

### **Übergangsdiagramme (Endliche Automaten)**
Der Lexer basiert auf **Deterministischen Endlichen Automaten (DFA)**.

* **Prinzip:** Der Lexer startet bei Zustand 0. Er liest ein Zeichen und folgt dem Pfeil, der mit diesem Zeichen beschriftet ist, zum nächsten Zustand.
* **Ziel:** Einen "akzeptierenden Zustand" (Endzustand) erreichen. Das bedeutet, ein gültiges Token (z. B. eine Zahl, ein Operator) wurde erkannt.
* **Verzweigung:** Wenn der Lexer ein `<` liest, weiß er noch nicht, welches Token es wird. Er muss weiterlesen, um zu unterscheiden, ob es `<` (kleiner), `<=` (kleiner gleich) oder `<>` (ungleich) ist.

### **"Retract"-Problem (Lookahead)**
Dies ist das wichtigste technische Detail beim Scannen.

* **Das Problem:** Oft weiß der Automat erst, dass ein Token zu Ende ist, wenn er bereits ein Zeichen *zu viel* gelesen hat, das gar nicht mehr dazu gehört.
* **Beispiel:** Der Lexer soll `>` erkennen.
  1.  Er liest `>`. (Könnte auch der Anfang von `>=` sein).
  2.  Er liest das nächste Zeichen, z. B. ein `a` (vom Variablennamen `anzahl`).
  3.  Erkenntnis: Es ist kein `=`, also war das Token `>` hier zu Ende.
* **Die Aktion (Retract):** Das Zeichen `a` wurde schon "konsumiert". Es muss nun **zurück in den Eingabepuffer geschoben** werden, damit es beim *nächsten* Aufruf des Lexers als erstes Zeichen gelesen wird. In Diagrammen wird dies oft mit einem Sternchen (`*`) am Endzustand markiert.

### **Identifier (IDs) vs. Keywords**
Automaten können strukturell kaum zwischen Variablennamen (IDs) und Schlüsselwörtern unterscheiden, da beide aus Buchstabenfolgen bestehen.

* **Falscher Ansatz:** Für jedes Schlüsselwort (`if`, `while`, `return`) einen eigenen Pfad im Automaten bauen. Das würde den Automaten riesig machen.
* **Richtiger Ansatz:**
  1.  Der Automat hat nur einen generischen Pfad für "Wörter" (Buchstabe gefolgt von Buchstaben/Zahlen).
  2.  Ist das Wort fertig eingelesen, wird in einer **Symboltabelle** (Liste reservierter Wörter) nachgeschlagen.
  3.  **Logik:** Steht das Wort in der Liste? $\rightarrow$ Token `KEYWORD`. Wenn nicht $\rightarrow$ Token `ID`.

## **Automaten**
Für Theorie-Aufgaben ist der Unterschied der Automatentypen wichtig:

* **NFA (Nicht-deterministisch):** Erlaubt "Raten". Es kann von einem Zustand mehrere Pfeile für das *gleiche* Zeichen geben (oder Sprünge ohne Zeichen). Gut für Menschen zum Entwerfen, schlecht für Computer.
* **DFA (Deterministisch):** Eindeutig. Für jedes Zeichen gibt es genau einen definierten Weg.
* **Workflow:** Man definiert Muster als *Reguläre Ausdrücke*, wandelt diese (theoretisch) in NFAs um und optimiert sie schließlich zu DFAs, um sie effizient zu programmieren.

### **Formale Definition**
Ein Automat besteht immer aus 5 Teilen $(\Sigma, S, \delta, s_0, S_F)$:

1.  **$\Sigma$ (Alphabet):** Welche Zeichen darf ich lesen? (z. B. `a`, `b`, `0`, `1`).
2.  **$S$ (Zustände):** Alle Kreise im Bild.
3.  **$s_0$ (Start):** Der Start-Pfeil (hier geht's los).
4.  **$S_F$ (Endzustände):** Die doppelten Kreise (hier ist das Wort gültig).
5.  **$\delta$ (Übergänge):** Die Pfeile zwischen den Kreisen (Regelwerk: Wo gehe ich hin bei welchem Zeichen?).

### **Tabellengetriebener Ansatz**

Anstatt den Automaten durch verschachtelte Kontrollstrukturen (wie `switch-case`) hart zu kodieren, wird die Übergangsfunktion $\delta$ in einer **Datenstruktur** abgebildet.

**Übergangsmatrix**
Man verwendet eine zweidimensionale Tabelle (Matrix/Array), um die Zustandsübergänge zu speichern.

* **Zeilen:** Repräsentieren die Menge aller Zustände $S$.
* **Spalten:** Repräsentieren das Eingabealphabet $\Sigma$.

**Zugriff**
Der nächste Zustand wird durch einen direkten Tabellenzugriff ermittelt:
`Table[aktueller_Zustand][eingabe_Zeichen] = ziel_Zustand`

**Fehlerbehandlung**
Ein **leerer Eintrag** (oder ein spezieller Fehlerwert) in der Matrix an der Stelle `[j][k]` bedeutet, dass für den Zustand `j` mit dem Zeichen `k` kein Übergang definiert ist. Dies entspricht einem Syntaxfehler im Eingabecode.

### **NFA zu DFA (Büchi-Algorithmus)**

1. **Ziel:**
  Umwandlung eines **nichtdeterministischen Automaten (NFA)** in einen **deterministischen Automaten (DFA)**.

1. **Hauptoperationen:**

  * **ε-closure:** Berechnung aller Zustände, die durch ε-Übergänge (ohne Eingabezeichen) erreichbar sind.
  * **move:** Bestimmung, wohin man mit einem Eingabesymbol von einem Zustand aus geht.

3. **Ablauf:**

  * Beginne mit der **ε-closure** des Startzustands des NFA.
  * Berechne für jedes Eingabesymbol **move(T, a)** und dann **ε-closure(move(T, a))**.
  * Wiederhole, bis alle Zustände des DFA bestimmt sind.

4. **Ergebnis:**
  Ein deterministischer Automat (DFA) mit einer Menge von NFA-Zuständen als DFA-Zustände.

### **Regex zu NFA (Yamada-Thompson)**

Der Yamada-Thompson-Algorithmus ist ein Verfahren zur Umwandlung eines **regulären Ausdrucks (Regex)** in einen **NFA**. Dabei wird der reguläre Ausdruck schrittweise in eine **Zustandsmaschine** umgewandelt.

### **Schritte:**

1. **Regex aufteilen:** Der reguläre Ausdruck wird in seine Grundbausteine (Operationen wie Konkatenation, Vereinigung, Kleene-Stern) zerlegt.
2. **Teil-NFAs erstellen:** Für jede Operation (z. B. „|“ für Vereinigung, „*“ für Kleene-Stern) wird ein eigener NFA konstruiert.
3. **Zustände verknüpfen:** Diese Teil-NFAs werden dann miteinander verknüpft, um den vollständigen NFA zu bilden.

## **Effizienz**

* **NFA (Der "Sichere"):**
  * **Bau:** Sehr schnell und braucht wenig Speicher ($O(|r|)$).
  * **Laufzeit:** Etwas langsamer, weil er beim Lesen des Textes mehrere Zustände gleichzeitig verwalten muss.
* **DFA (Der "Schnelle, aber Riskante"):**
  * **Bau:** Kann extrem lange dauern und den Speicher sprengen (exponentielles Wachstum der Zustände möglich).
  * **Laufzeit:** Unschlagbar schnell ($O(|x|)$), da er pro Zeichen immer nur exakt einen Schritt macht.

Obwohl der DFA beim Scannen schneller wäre, nutzen viele Tools (Scanner-Generatoren) lieber die **NFA-Simulation**.



