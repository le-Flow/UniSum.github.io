### 1. Replikation und das Konsistenzproblem

Replikation, also das Kopieren von Daten auf mehrere Rechner, wird genutzt, um die **Zuverlässigkeit** (Schutz vor Ausfall) und die **Skalierbarkeit** (Lastverteilung) zu erhöhen.

* **Das Hauptproblem:** Um Replikate konsistent zu halten, müssen alle Operationen (insbesondere kollidierende) auf allen Kopien in derselben Reihenfolge ausgeführt werden.
* **Konflikte:**
    * **Lese-Schreib-Konflikt:** Ein Lesevorgang ist gleichzeitig mit einem Schreibvorgang.
    * **Schreib-Schreib-Konflikt:** Zwei Schreibvorgänge sind gleichzeitig.
* **Die Lösung (Kompromiss):** Die Gewährleistung einer strikten globalen Ordnung ist teuer und langsam. Daher werden **Konsistenzmodelle geschwächt**, um eine bessere Skalierbarkeit zu erreichen.

---

### 2. Datenzentrierte Konsistenzmodelle

Ein **Konsistenzmodell** ist ein Vertrag zwischen dem Datenspeicher und den Prozessen. Es definiert, welches Ergebnis Leseoperationen zurückliefern, wenn gleichzeitig Schreiboperationen stattfinden.

Man unterscheidet zwischen starken Modellen (strikte Regeln) und schwachen Modellen (gelockerte Regeln).

---

### 3. Starke Konsistenzmodelle

Diese Modelle bieten starke Garantien über die Reihenfolge der Operationen, die für alle Prozesse sichtbar sind.

* **Strenge Konsistenz (Strict Consistency)**
    * **Definition:** Jeder Lesevorgang liefert den Wert des **jüngsten Schreibvorgangs** (basierend auf der Echtzeit).
    * **Problem:** In einem verteilten System gibt es keine globale Uhr, daher ist das Konzept des "jüngsten" Zeitpunkts kaum umsetzbar.
* **Sequentielle Konsistenz (Sequential Consistency)**
    * **Definition:** Das Ergebnis ist dasselbe, als ob alle Operationen aller Prozesse in *irgendeiner* sequentiellen Reihenfolge (Interleaving) ausgeführt worden wären, wobei die *programminterne Reihenfolge* jedes einzelnen Prozesses erhalten bleibt.
    * **Bedeutung:** Es gibt *eine* globale Reihenfolge, die alle Prozesse "sehen" (z.B. W(a) vor W(b)), aber diese Reihenfolge muss nicht der Echtzeit entsprechen.
* **Kausale Konsistenz (Causal Consistency)**
    * **Definition:** Nur **kausal zusammenhängende** Schreibvorgänge müssen von allen Prozessen in derselben (kausalen) Reihenfolge gesehen werden.
    * **Bedeutung:** Gleichzeitige (konkurrierende) Schreibvorgänge können von verschiedenen Prozessen in unterschiedlicher Reihenfolge gesehen werden.
* **FIFO-Konsistenz (FIFO Consistency)**
    * **Definition:** Schreibvorgänge von *einem einzelnen Prozess* werden von allen anderen Prozessen in der Reihenfolge gesehen, in der sie ausgeführt wurden.
    * **Bedeutung:** Schreibvorgänge von *verschiedenen* Prozessen können in unterschiedlicher Reihenfolge gesehen werden.

---

### 4. Schwache Konsistenzmodelle

Diese Modelle lockern die Regeln stark und verlassen sich auf **Synchronisationsvariablen** (wie Mutexe oder Sperren), um Konsistenz nur dann explizit zu erzwingen, wenn es vom Programm angefordert wird.

* **Schwache Konsistenz (Weak Consistency)**
    * **Definition:** Es wird nicht garantiert, dass einzelne Schreibvorgänge sofort sichtbar sind. Konsistenz wird nur an **Synchronisationspunkten** erzwungen.
    * **Regeln:**
        1.  Operationen auf Synchronisationsvariablen selbst sind sequentiell konsistent.
        2.  Bevor eine Synchronisationsoperation (z.B. `release()`) durchgeführt wird, müssen alle vorherigen Schreibvorgänge auf den Daten abgeschlossen und für alle sichtbar sein.
        3.  Bevor auf Daten zugegriffen wird (Lesen/Schreiben), müssen alle vorherigen Synchronisationsoperationen abgeschlossen sein.
* **Weitere Modelle:**
    * **Freigabekonsistenz (Release):** Gemeinsame Daten sind konsistent, wenn eine Synchronisationsvariable *freigegeben* wird.
    * **Eintrittskonsistenz (Entry):** Gemeinsame Daten sind konsistent, wenn eine Synchronisationsvariable *erlangt* (acquire) wird.

---

### 5. Klienten-zentrierte Konsistenz

Diese Perspektive konzentriert sich nicht auf die globale Sicht aller Prozesse, sondern auf die Garantien, die ein *einzelner Klient* erhält (besonders relevant für mobile Nutzer, die auf verschiedene Replikate zugreifen).

* **Monotones Lesen (Monotonic Reads)**
    * **Definition:** Wenn ein Prozess einen Wert $x$ liest, liefert jeder *nachfolgende* Lesevorgang desselben Prozesses denselben oder einen *neueren* Wert. Man sieht nie "die Vergangenheit".
    * **Beispiel:** Eine E-Mail-Inbox, die auf einem Server gelesene Mails anzeigt, wird auf einem anderen Server nicht plötzlich wieder als "ungelesen" angezeigt.

---

### 6. Eventual Consistency & Stufenlose Konsistenz

Diese Modelle sind für hochskalierbare Systeme (z.B. Cloud-Datenbanken) relevant, die Verfügbarkeit über sofortige Konsistenz stellen.

* **Eventual Consistency**
    * **Definition:** Wenn keine neuen Aktualisierungen (Schreibvorgänge) an einem Datenelement vorgenommen werden, konvergieren *irgendwann* (eventually) alle Replikate auf denselben, zuletzt geschriebenen Wert.
    * **Kontext:** Dies stellt Verfügbarkeit trotz Netzwerkpartitionen sicher (siehe CAP-Theorem).
    * **Klienten-zentrierte Sicht (Definitionen für "Eventual"):**
        * **Monotones Lesen:** Man sieht nie veraltete Daten, nachdem man neuere gesehen hat.
        * **Lies Deine Schreibvorgänge (Read Your Writes):** Ein Prozess sieht immer seine eigenen, (gerade eben) geschriebenen Werte.
        * **Schreibvorgänge folgen Lesevorgängen (Writes Follow Reads):** Kausale Abhängigkeiten (Lesen eines Werts, dann Schreiben eines neuen Werts) werden eingehalten.
* **Stufenlose Konsistenz (Tunable Consistency)**
    * **Idee:** Statt einer binären (ja/nein) Konsistenz wird der *Grad der Inkonsistenz* gemessen und toleriert.
    * **Conit (Consistency Unit):** Die Dateneinheit, für die die Metriken gelten (z.B. ein einzelner Datensatz).
    * **Metriken (Abweichungen):**
        1.  **Veralterungsgrad (Staleness):** Wie alt sind die Daten im Replikat?
        2.  **Ordnungsabweichung (Order deviation):** Wie viele Updates wurden in der falschen Reihenfolge angewendet?
        3.  **Numerische Abweichung (Numerical deviation):** Wie groß ist der Zahlenunterschied zwischen den Werten der Replikate?