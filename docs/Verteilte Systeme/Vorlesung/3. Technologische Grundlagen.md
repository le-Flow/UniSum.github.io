### 1. Threads

Threads sind "minimale Software-Prozessoren", die es ermöglichen, virtuelle Prozessoren in Software zu erstellen. Ein **Prozess** ist dabei der Kontext (der Software-Prozessor), in dem ein oder mehrere Threads ausgeführt werden.

* **Implementierungsansätze:**
  * **Benutzerebene (User-level):** Die Thread-Verwaltung findet komplett im Userspace statt.
    * **Vorteil:** Extrem effizient, da kein Kernel-Trap für Thread-Operationen nötig ist.
    * **Nachteil:** Wenn ein Thread einen blockierenden Systemaufruf (z.B. I/O) tätigt, blockiert der Kernel den *gesamten Prozess*, und damit alle anderen Threads in diesem Prozess.
  * **Kernel-Ebene (Kernel-level):** Der Kernel verwaltet die Threads. Jede Thread-Operation ist ein Systemaufruf.
    * **Vorteil:** Blockierende Aufrufe sind kein Problem; der Kernel kann einfach einen anderen Thread desselben Prozesses einplanen (schedulen).
    * **Nachteil:** Geringere Effizienz, da jede Operation einen Trap in den Kernel erfordert.
* **Lightweight Process (LWP):**
  * Eine hybride Lösung, die Kernel-Ebene und Benutzerebene mischt.
  * Der Kernel stellt mehrere Kernel-Threads (LWPs) für einen Prozess bereit.
  * Die User-level Thread-Bibliothek verteilt die (vielen) User-Threads auf die (wenigeren) Kernel-Threads (N:M-Beziehung).
  * Context-Switches zwischen User-Threads können im Userspace stattfinden (effizient), blockierende Aufrufe blockieren nur den LWP, nicht den ganzen Prozess.
* **Threads in Verteilten Systemen:**
  * **Multithreaded Clients:** Hauptmotivation ist das **Verbergen von Netzwerklatenz**.
    * *Beispiel Webbrowser:* Ein Thread pro Datei (z.B. Bild), um mehrere Dateien parallel über separate TCP-Verbindungen zu laden.
    * *Beispiel RPC:* Mehrere RPCs können parallel (jeder in einem eigenen Thread) ausgeführt werden, was bei Anfragen an verschiedene Server zu linearem Geschwindigkeitszuwachs führen kann.
  * **Multithreaded Server:** Hauptmotivationen sind **verbesserte Leistung** und **einfachere Softwarestruktur**.
    * *Leistung:* Das Starten eines Threads ist "billiger" als das eines neuen Prozesses; Latenz kann verborgen werden, indem auf die nächste Anfrage reagiert wird, während eine vorherige auf I/O wartet.
    * *Struktur:* Erlaubt die Nutzung einfacher, blockierender Aufrufe, was den Kontrollfluss vereinfacht.
    * *Architektur:* Oft als **Dispatcher-Thread** (nimmt Anfragen entgegen) und Pool von **Worker-Threads** (bearbeiten die Anfragen) implementiert.

---

### 2. Virtualisierung: Grundlagen & Konzepte

Virtualisierung ist das Erweitern oder Ersetzen einer Schnittstelle, um ein anderes System zu imitieren. Ein **Virtual Machine Monitor (VMM)**, auch Hypervisor genannt, ist die Software, die virtuelle Maschinen (VMs) erstellt und verwaltet.

* **Rolle des VMM:**
  * Der VMM besitzt die realen Hardwareressourcen.
  * Er teilt Ressourcen zu durch **Time-Sharing** (z.B. CPU) oder **Partitionierung** (z.B. Festplatte).
  * Nicht vorhandene Ressourcen werden vom VMM **emuliert**.
* **Zustandsmanagement (State Management):**
  * Um zwischen VMs zu wechseln, muss der VMM den Zustand (Register) der VM sichern und den der nächsten laden.
  * **Ansatz 1 (Indirektion):** Der Prozessor hat nur einen "Register Block Pointer", der auf den Speichersatz der aktiven VM im VMM-Speicher zeigt. Umschalten = nur Pointer ändern.
  * **Ansatz 2 (Kopieren):** Der VMM kopiert die Registerwerte beim Umschalten explizit zwischen Prozessor und VMM-Speicher hin und her.
* **Native vs. Gehostete VMMs:**
  * **Native VM (Typ 1):** Der VMM läuft direkt auf der Hardware (z.B. VMware ESXi).
  * **User-mode hosted VM (Typ 2):** Der VMM läuft als normale Anwendung auf einem Host-Betriebssystem (z.B. VirtualBox).
  * **Dual-mode hosted VM (Typ 2):** Der VMM ist als Modul im Host-Betriebssystem integriert (z.B. Parallels für Mac).

---

### 3. Virtualisierung: Kontrolle & Effizienz

Das Hauptproblem für einen VMM ist, die Kontrolle über die Systemressourcen zu behalten, obwohl das Gast-Betriebssystem glaubt, es würde die Hardware direkt steuern.

* **Popek & Goldberg (1974) Kriterien:** Ein "echter" VMM muss drei Kriterien erfüllen:
  1.  **Effizienz:** "Harmlose" (unbedenkliche) Anweisungen müssen nativ (direkt auf der CPU) ausgeführt werden.
  2.  **Ressourcenkontrolle:** Gast-VMs dürfen die Systemressourcen nicht ändern können (Isolierung). Das Gast-OS muss daher im **Benutzermodus** laufen.
  3.  **Äquivalenz:** Ein Programm muss sich auf der VM (nahezu) genauso verhalten wie auf nativer Hardware (Ausnahme: Performance, Timing).
* **Das Virtualisierungs-Theorem:**
  * **Sensitive Instructions:** Befehle, die die Ressourcenkonfiguration ändern (control-sensitive) oder deren Verhalten von der Konfiguration abhängt (behavior-sensitive).
  * **Privileged Instructions:** Befehle, die einen *Trap* (Fehler) auslösen, wenn sie im Benutzermodus ausgeführt werden.
  * **Theorem:** Ein VMM kann nur dann effizient konstruiert werden, wenn die Menge der **sensitiven** Instruktionen eine Teilmenge der **privilegierten** Instruktionen ist.
  * *Einfacher gesagt:* Jeder Befehl, der "gefährlich" (sensitiv) ist, *muss* einen Trap auslösen, wenn das Gast-OS (im User-Mode) ihn ausführt. So erhält der VMM die Kontrolle zurück.
* **Das Problem "alter" Architekturen (z.B. x86):**
  * Die Bedingung ist **nicht** erfüllt.
  * Es gibt **"kritische Anweisungen"**: Das sind Befehle, die *sensitiv*, aber *nicht privilegiert* sind. Sie lösen keinen Trap aus und erlauben dem Gast-OS, den VMM zu umgehen oder Systemzustände zu ändern (z.B. der `POPF`-Befehl).
* **Lösungen für nicht-virtualisierbare Architekturen:**
  1.  **Binäre Übersetzung (Binary Translation):** Der VMM scannt den Code des Gast-OS zur Laufzeit. Kritische Anweisungen werden erkannt ("Patched Program") und durch Code ersetzt, der stattdessen den VMM aufruft (Emulation). Für die Effizienz werden übersetzte Code-Blöcke in einem **Code Cache** gespeichert.
  2.  **Paravirtualisierung:** Der Code des Gast-Betriebssystems wird *im Voraus geändert*. Kritische Befehle werden durch explizite Aufrufe an den VMM (sog. "Hypercalls") ersetzt. Nachteil: Es wird ein speziell angepasstes Gast-OS benötigt.
* **Moderne Architekturen (Intel VT, ARM VHE):** Diese ISAs sind nach den Popek/Goldberg-Kriterien konstruiert und beheben das Problem der "kritischen Anweisungen" in Hardware.

---

### 4. Container

Container (popularisiert durch Docker) sind eine Form der "leichtgewichtigen Virtualisierung". Der fundamentale Unterschied zu VMs ist, dass Container **das zugrundeliegende Betriebssystem (Host OS) teilen**.

* **Isolations-Mechanismen:** Anstelle von Hardware-Virtualisierung nutzen Container Kernel-Funktionen zur Isolierung:
  * **Namespaces:** Isolieren die "Sicht" des Containers auf Systemressourcen (z.B. eigene Prozess-IDs, Netzwerk-Interfaces, User-IDs).
  * **Union File System:** Dateisysteme werden in Schichten aufgebaut. Ein "Base Image" (z.B. Ubuntu) ist read-only und wird geteilt; nur die Änderungen des Containers werden in eine separate, beschreibbare Schicht geschrieben.
  * **Control Groups (cgroups):** Kontrollieren und limitieren die Ressourcennutzung (CPU, Speicher) für Prozessgruppen.

---

### 5. VMs & Container in Verteilten Systemen

Die Hauptanwendung für Virtualisierungstechnologien in verteilten Systemen ist das **Cloud Computing**. Sie ermöglichen die effiziente Zuteilung von Ressourcen bei gleichzeitiger Wahrung der Isolationsanforderungen.

* **IaaS (Infrastructure-as-a-Service):** Bietet virtuelle Hardware-Ressourcen (z.B. virtuelle Rechner wie Amazon EC2).
* **PaaS (Platform-as-a-Service):** Bietet eine Plattform zur Anwendungsentwicklung und -ausführung (z.B. Heroku).
* **SaaS (Software-as-a-Service):** Bietet fertige Software-Anwendungen (z.B. Webmail).