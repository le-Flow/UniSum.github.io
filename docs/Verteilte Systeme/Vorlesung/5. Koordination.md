### 1. Aufgaben: Koordination & Synchronisation

Koordination in verteilten Systemen befasst sich mit der Organisation von Interaktionen und der Synchronisation von Prozessen und Daten.

* **Prozesssynchronisation:** Ein Prozess wartet auf einen anderen, um eine Operation abzuschließen.
* **Datensynchronisation:** Sicherstellen, dass zwei Datenmengen identisch sind.
* **Koordination:** Organisation von Interaktionen und Abhängigkeiten im System.

---

### 2. Physikalische Uhrensynchronisation

Das Hauptproblem ist, dass jeder Computer eine eigene, ungenaue Hardware-Uhr hat. Ohne Synchronisation können Fehler entstehen (z.B. beim `make`-Kommando). Das Ziel ist, die Uhren an die "exakte" **UTC** (Universal Coordinated Time) anzugleichen.

* **UTC:** Basiert auf Atomuhren (TAI - Internationale Atomzeit), wird aber durch **Schaltsekunden** an die Erdrotation (Sonnentag) angepasst.
* **Problem (Drift):** Lokale Uhren sind nicht ideal. Ihre Geschwindigkeit ($dC/dt$) weicht von 1 ab. Die Abweichung wird durch die **Driftrate $\rho$** (rho) beschrieben.
* **Ziel:** Die Abweichung zwischen zwei Uhren soll nie größer als $\delta$ (delta) sein.
* **Lösung:** Uhren müssen mindestens alle $\Delta t \le \delta / (2\rho)$ Sekunden neu synchronisiert werden.
* **Regel:** Die Zeit darf **niemals rückwärts laufen**. Schnelle Uhren müssen stattdessen verlangsamt werden (ihre Taktrate wird angepasst).

---

### 3. Network Time Protocol (NTP)

NTP (basierend auf Cristians Algorithmus) ist ein praktisches Verfahren zur Synchronisation physikalischer Uhren. Ein Client fragt einen Zeitserver nach der Zeit.

* **Messung:** Der Client misst vier Zeitstempel: $T_1$ (Anfrage gesendet), $T_2$ (Anfrage empfangen), $T_3$ (Antwort gesendet), $T_4$ (Antwort empfangen).
* **Berechnung (Offset):** Der Client berechnet den Zeit-Offset $\Theta$ (theta) seiner Uhr relativ zum Server: $\Theta = ((T_2 - T_1) + (T_3 - T_4)) / 2$.
* **Berechnung (Verzögerung):** Er berechnet auch die durchschnittliche Einweg-Verzögerung $\delta$ (delta): $\delta = ((T_4 - T_1) - (T_3 - T_2)) / 2$.
* **Auswahl:** Es werden mehrere Paare $(\Theta, \delta)$ berechnet, und das Paar mit der *kleinsten Verzögerung* $\delta$ wird zur Korrektur verwendet.
* **NTP Strata:** Um Last zu verteilen und Schleifen zu vermeiden, sind Server in Schichten (Strata) organisiert.
    * **Stratum 0:** Atomuhren (die Referenz).
    * **Stratum 1:** Server, die direkt mit Stratum 0 synchronisieren.
    * **Stratum n+1:** Server, die mit Stratum $n$ synchronisieren.

---

### 4. Logische Zeit und Reihenfolge

Oft ist nicht die exakte physikalische Zeit wichtig, sondern nur die *relative Reihenfolge* von Ereignissen. Dies wird durch die **Happened-Before-Relation ($\rightarrow$)** und **Logische Uhren (Lamport Clocks)** erreicht.

* **Happened-Before Relation ($\rightarrow$):** Eine partielle Ordnung, definiert durch drei Regeln:
    1.  **Im selben Prozess:** Wenn $a$ vor $b$ im selben Prozess passiert, dann $a \rightarrow b$.
    2.  **Nachrichten:** Wenn $a$ das Senden und $b$ der Empfang derselben Nachricht ist, dann $a \rightarrow b$.
    3.  **Transitivität:** Wenn $a \rightarrow b$ und $b \rightarrow c$, dann $a \rightarrow c$.
* **Lamports Algorithmus:** Weist jedem Ereignis einen Zeitstempel (einen Zähler $C$) zu, der die Happened-Before-Relation abbildet.
    * **Regel 1 (Lokales Ereignis):** $C_i \leftarrow C_i + 1$.
    * **Regel 2 (Senden):** $C_i \leftarrow C_i + 1$; die Nachricht erhält den Zeitstempel $T_m = C_i$.
    * **Regel 3 (Empfangen):** Beim Empfang von $T_m$, setze $C_j \leftarrow max(C_j, T_m) + 1$.

---

### 5. Vector Clocks

Lamport Clocks haben eine Schwäche: Wenn $C(a) < C(b)$, heißt das *nicht* zwingend, dass $a \rightarrow b$. **Vector Clocks** lösen dieses Problem und erfassen die Kausalität exakt.

* **Struktur:** Jeder Prozess $P_i$ hat einen Vektor $VC_i[1..n]$. $VC_i[j]$ zählt die Ereignisse bei Prozess $P_j$, von denen $P_i$ weiß.
* **Regel 1 (Lokales Ereignis):** $VC_i[i] \leftarrow VC_i[i] + 1$.
* **Regel 2 (Senden):** $VC_i[i] \leftarrow VC_i[i] + 1$; sende den gesamten Vektor $VC_i$ mit der Nachricht.
* **Regel 3 (Empfangen):** Beim Empfang von $vt(m)$ von $P_i$:
    1.  $VC_j[k] \leftarrow max(VC_j[k], vt(m)[k])$ für alle $k$.
    2.  $VC_j[j] \leftarrow VC_j[j] + 1$.

---

### 6. Totale Ordnung

In manchen Systemen (z.B. replizierte Datenbanken) reicht eine partielle Ordnung nicht aus. Gleichzeitige Updates müssen bei allen Replikaten in derselben Reihenfolge angewendet werden, um Inkonsistenzen zu vermeiden.

* **Problem:** Replikat R1 wendet (Einzahlung + Zinsen) an, R2 wendet (Zinsen + Einzahlung) an. Die Endergebnisse sind unterschiedlich.
* **Lösung:** **Total geordneter Multicast**, der sicherstellt, dass alle Prozesse alle Nachrichten in derselben globalen Reihenfolge empfangen.

---

### 7. Gegenseitiger Ausschluss (Mutex)

Ein klassisches Problem, bei dem mehrere Prozesse exklusiven Zugriff auf eine gemeinsame Ressource (einen kritischen Abschnitt) benötigen.

* **Ansatz 1: Zentralisierter Algorithmus:**
    * Ein Prozess wird zum **Koordinator** gewählt.
    * Wer in den kritischen Abschnitt will, schickt eine `Request`-Nachricht an den Koordinator.
    * Der Koordinator antwortet mit `OK`. Wenn die Ressource belegt ist, kommt der `Request` in eine Warteschlange.
    * Nach Verlassen wird eine `Release`-Nachricht gesendet.
    * **Problem:** Der Koordinator ist ein **Single Point of Failure**.
* **Ansatz 2: Dezentralisierter Algorithmus:**
    * Die Ressource wird $n$-mal repliziert, jede mit einem Koordinator.
    * Ein Prozess benötigt die Erlaubnis von einer **Mehrheit ($m > n/2$)** der Koordinatoren.
    * **Probleme:** Nur probabilistisch korrekt und anfällig für "Verhungern" (keiner kriegt eine Mehrheit).
* **Ansatz 3: Praktische Systeme (z.B. Zookeeper):**
    * Verwenden oft einen (hochverfügbaren) zentralisierten Koordinator-Dienst wie **Apache Zookeeper**.
    * Zookeeper wird für Cluster-Management, Leader-Wahl und Konfiguration in Systemen wie Hadoop und Kafka genutzt.

---

### 8. Wahl-Algorithmen (Election)

Diese Algorithmen werden benötigt, um dynamisch einen Koordinator (Leader) zu bestimmen, z.B. wenn der alte ausfällt. Statische Wahlen sind ein Single-Point-of-Failure.

* **Der Bully-Algorithmus:**
    * **Idee:** Der Prozess mit der höchsten Priorität (höchste ID-Nummer) "mobbt" sich an die Spitze und wird Leader.
    * **Ablauf:**
        1.  Prozess $P$ stellt Ausfall des Leaders fest und startet eine Wahl. Er sendet `Election`-Nachrichten an alle Prozesse mit *höherer* ID.
        2.  Wenn ein höherer Prozess $Q$ die Nachricht empfängt, antwortet er mit `OK`, $P$ ist aus dem Rennen und $Q$ startet selbst eine Wahl.
        3.  Wenn $P$ *keine* `OK`-Antwort erhält (weil alle höheren ausgefallen sind), gewinnt $P$ die Wahl und sendet eine `Coordinator`-Nachricht an alle.
* **Ring-Algorithmus:**
    * **Idee:** Die Prozesse sind in einem logischen Ring angeordnet.
    * **Ablauf:**
        1.  $P$ startet eine Wahl und sendet eine `Election`-Nachricht mit einer "Alive-Liste" an seinen Nachfolger.
        2.  Jeder Prozess fügt seine ID der Liste hinzu und leitet sie weiter.
        3.  Wenn die Nachricht wieder beim Initiator $P$ ankommt, enthält sie eine Liste aller aktiven Prozesse.
        4.  $P$ sendet eine `Coordinator`-Nachricht an alle, die den Prozess mit der höchsten Priorität aus der Liste zum neuen Leader ernennt.
* **Praktische Systeme:** Zookeeper und Raft sind gängige Systeme zur Implementierung von Leader-Wahlen.